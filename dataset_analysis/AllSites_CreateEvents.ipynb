{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d85bcde-fe45-4570-89d9-8872291c4ae5",
   "metadata": {},
   "source": [
    "# All Sites- Create Duration Events\n",
    "* calculating duration of unloading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8ae2b4-167c-43ad-b3fb-f70925f35ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "%matplotlib widget\n",
    "\n",
    "# plotting packages \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# interactive plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots # adding for subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# data packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "import csv \n",
    "import copy \n",
    "import os.path "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c7c90d-29f8-49c9-a73d-7c4b1f81994d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bef8be-1090-489b-b65d-733cca90454f",
   "metadata": {},
   "source": [
    "## Sodankyla Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbf75a4-9342-42c5-a33d-eb6a3ca9970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN MET DATA \n",
    "sod =  pd.read_csv(\"/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/Sodankyla/SOD_1819_1hr_cleaned.csv\")\n",
    "sod['datetime'] = pd.to_datetime(sod['datetime'])\n",
    "\n",
    "# OPEN CLASSIFICATIONS\n",
    "sodobs = pd.read_csv(\"/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/Classifications/datetimeformat_classifications_sodankyla2019_type.csv\")\n",
    "sodobs['datetime'] = pd.to_datetime(sodobs['datetime'])\n",
    "sodobs.dropna(axis=0, how='all', inplace=True) #removing row is entire row is NAN #careful with this, without datetime a lot gets removed \n",
    "\n",
    "# MERGE\n",
    "soddf = pd.merge(sod, sodobs, how='outer', on='datetime')\n",
    "soddf.index = pd.DatetimeIndex(soddf['datetime'])\n",
    "# soddf.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "# Create seperate df for only snow in the canopy timesteps \n",
    "sod_df_unload = soddf.copy(deep=True)\n",
    "sod_df_unload = sod_df_unload.dropna(axis=0, subset=['CD'])\n",
    "\n",
    "# Have to remove all nans for this plotting to work.... need to come back to this \n",
    "# sod_df_unload.dropna(inplace=True)\n",
    "\n",
    "# Create sunlit column\n",
    "sod_df_unload['Sunlit'] = sod_df_unload.E.copy(deep=True)\n",
    "sod_df_unload.Sunlit.mask(sod_df_unload.Sunlit == 0, \"Not Sunlit\", inplace=True)\n",
    "sod_df_unload.Sunlit.mask(sod_df_unload.Sunlit == 1, \"Sunlit Canopy\", inplace=True)\n",
    "\n",
    "# Create unloading classification column\n",
    "sod_df_unload['Classification'] = sod_df_unload.CD.copy(deep=True)\n",
    "sod_df_unload.Classification.mask(sod_df_unload.Classification == 0, \"Snow Unloading\", inplace=True)\n",
    "sod_df_unload.Classification.mask(sod_df_unload.Classification == 1, \"Snow Staying\", inplace=True)\n",
    "\n",
    "sod_df_snowstay   = sod_df_unload.where(sod_df_unload.CD == 1).dropna(axis=0, subset=['CD']) # where CD == 1, meaning Snow Staying, make that snowstaydf\n",
    "sod_df_snowunload = sod_df_unload.where(sod_df_unload.CD == 0).dropna(axis=0, subset=['CD']) # where CD == 0, meaning Snow Unloading, make that snowunloaddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1ea0bd-ec12-4bb2-ba7d-72b42f5049fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# https://plotly.com/python/marker-style\n",
    "# TYPE-------------------------------------------------------\n",
    "# Create symbols for type 1 and type 2 \n",
    "sod_df_unload['Typesymbol'] = np.nan\n",
    "\n",
    "# open diamont for type 1, diamond for type 2, open x circle for no classification\n",
    "sod_df_unload['Typesymbol'].mask(sod_df_unload['Type'] == 1, 102, inplace=True) \n",
    "sod_df_unload['Typesymbol'].mask(sod_df_unload['Type'] == 2., 2, inplace=True)    \n",
    "\n",
    "# then fillna with 128 for circle with x through it \n",
    "sod_df_unload['Typesymbol'] = sod_df_unload['Typesymbol'].fillna(128)  \n",
    "\n",
    "# # SNOW-------------------------------------------------------\n",
    "# Create symbols for sunlit or not\n",
    "sod_df_unload['Snowsymbol'] = np.nan\n",
    "\n",
    "# open triangle for melt, diamond for sub, open x circle for no classification\n",
    "sod_df_unload['Snowsymbol'].mask(sod_df_unload['Snow'] == 'mass', 105, inplace=True) # this is working without fillna\n",
    "sod_df_unload['Snowsymbol'].mask(sod_df_unload['Snow'] == 'sub', 18, inplace=True)  \n",
    "sod_df_unload['Snowsymbol'].mask(sod_df_unload['Snow'] == 'melt', 2, inplace=True)    \n",
    "\n",
    "# then fillna with 128 for circle with x through it \n",
    "sod_df_unload['Snowsymbol'] = sod_df_unload['Snowsymbol'].fillna(128)  \n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019bf598-ed44-4b8d-8e1b-cc327707b1e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Laret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ac3131-abea-4624-8f37-c002bf97fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open met dataset\n",
    "opn  = pd.read_csv(\"/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/MetStations/Cleaned/opnc_hcass.csv\")\n",
    "opn['datetime'] = pd.to_datetime(opn['datetime'])\n",
    "\n",
    "# Open observations classifications \n",
    "obs = pd.read_csv(\"/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/Excel/Datetime/datetimeformat_ccg_classifications_only_cutdates_type.csv\")\n",
    "obs['datetime'] = pd.to_datetime(obs['datetime'])\n",
    "obs.dropna(axis=0, how='all', inplace=True) #removing row is entire row is NAN #careful with this, without datetime a lot gets removed\n",
    "\n",
    "# Merge them\n",
    "opndf = pd.merge(opn, obs, how='outer', on='datetime')\n",
    "opndf.index = pd.DatetimeIndex(opndf['datetime'])\n",
    "\n",
    "# Create seperate df for only snow in the canopy timesteps \n",
    "opn_df_unload = opndf.copy(deep=True)\n",
    "opn_df_unload = opn_df_unload.dropna(axis=0, subset=['CD'])\n",
    "\n",
    "# # Have to remove all nans for this plotting to work.... need to come back to this \n",
    "# opn_df_unload.dropna(inplace=True)\n",
    "\n",
    "# SPECIAL FOR LARET BECAUSE OF NAMES \n",
    "opn_df_unload['temp'] = opn_df_unload['AirTC_Avg'].copy(deep=True)\n",
    "opn_df_unload['shortwave'] = opn_df_unload['SWR_Avg'].copy(deep=True)\n",
    "opn_df_unload['windspeed'] = opn_df_unload['WS_ms_Avg'].copy(deep=True)\n",
    "\n",
    "# Create sunlit column\n",
    "opn_df_unload['Sunlit'] = opn_df_unload.E.copy(deep=True)\n",
    "opn_df_unload.Sunlit.mask(opn_df_unload.Sunlit == 0, \"Not Sunlit\", inplace=True)\n",
    "opn_df_unload.Sunlit.mask(opn_df_unload.Sunlit == 1, \"Sunlit Canopy\", inplace=True)\n",
    "\n",
    "# Create unloading classification column\n",
    "opn_df_unload['Classification'] = opn_df_unload.CD.copy(deep=True)\n",
    "opn_df_unload.Classification.mask(opn_df_unload.Classification == 0, \"Snow Unloading\", inplace=True)\n",
    "opn_df_unload.Classification.mask(opn_df_unload.Classification == 1, \"Snow Staying\", inplace=True)\n",
    "\n",
    "opn_df_snowstay   = opn_df_unload.where(opn_df_unload.CD == 1).dropna(axis=0, subset=['CD']) # where CD == 1, meaning Snow Staying, make that snowstaydf\n",
    "opn_df_snowunload = opn_df_unload.where(opn_df_unload.CD == 0).dropna(axis=0, subset=['CD']) # where CD == 0, meaning Snow Unloading, make that snowunloaddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30290256-c6e9-46ce-8a18-afbf0e0415d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# https://plotly.com/python/marker-style\n",
    "# TYPE-------------------------------------------------------\n",
    "# Create symbols for type 1 and type 2 \n",
    "opn_df_unload['Typesymbol'] = np.nan\n",
    "\n",
    "# open diamont for type 1, diamond for type 2, open x circle for no classification\n",
    "opn_df_unload['Typesymbol'].mask(opn_df_unload['Type'] == 1, 102, inplace=True) \n",
    "opn_df_unload['Typesymbol'].mask(opn_df_unload['Type'] == 2., 2, inplace=True)    \n",
    "\n",
    "# then fillna with 128 for circle with x through it \n",
    "opn_df_unload['Typesymbol'] = opn_df_unload['Typesymbol'].fillna(128)  \n",
    "\n",
    "# SNOW-------------------------------------------------------\n",
    "# Create symbols for sunlit or not\n",
    "opn_df_unload['Snowsymbol'] = np.nan\n",
    "\n",
    "# open triangle for melt, diamond for sub, open x circle for no classification\n",
    "opn_df_unload['Snowsymbol'].mask(opn_df_unload['Snow'] == 'mass', 105, inplace=True) # this is working without fillna\n",
    "opn_df_unload['Snowsymbol'].mask(opn_df_unload['Snow'] == 'sub', 18, inplace=True)  \n",
    "opn_df_unload['Snowsymbol'].mask(opn_df_unload['Snow'] == 'melt', 2, inplace=True)    \n",
    "\n",
    "# then fillna with 128 for circle with x through it \n",
    "opn_df_unload['Snowsymbol'] = opn_df_unload['Snowsymbol'].fillna(128)  \n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461c475-f074-451d-aa82-045d102baab7",
   "metadata": {},
   "source": [
    "## Niwot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d952f953-c486-4002-a6fe-98f6777a6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMERIFLUX MET DATA \n",
    "niwotflux =   pd.read_csv(\"/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/niwot_2017_ameriflux_unload1hr.csv\")\n",
    "niwotflux['datetime']  = pd.DatetimeIndex(niwotflux['datetime'])\n",
    "\n",
    "# OBSERVATIONS CLASSIFICATIONS\n",
    "niwotobs =  pd.read_csv(\"/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/Classifications/datetimeformat_classifications_niwot2017_type.csv\")\n",
    "niwotobs['datetime'] = pd.to_datetime(niwotobs['datetime'])\n",
    "\n",
    "niwotobs.dropna(axis=0, how='all', inplace=True) #removing row is entire row is NAN #careful with this, without datetime a lot gets removed \n",
    "\n",
    "# MERG THEM \n",
    "niwotdf = pd.merge(niwotflux, niwotobs, how='outer', on='datetime')\n",
    "niwotdf.index = pd.DatetimeIndex(niwotdf['datetime'])\n",
    "\n",
    "# Create seperate df for only snow in the canopy timesteps \n",
    "niwot_df_unload = niwotdf.copy(deep=True)\n",
    "niwot_df_unload = niwot_df_unload.dropna(axis=0, subset=['CD'])\n",
    "\n",
    "# # Have to remove all nans for this plotting to work.... need to come back to this \n",
    "# niwot_df_unload.dropna(inplace=True)\n",
    "\n",
    "# Create sunlit column\n",
    "niwot_df_unload['Sunlit'] = niwot_df_unload.E.copy(deep=True)\n",
    "niwot_df_unload.Sunlit.mask(niwot_df_unload.Sunlit == 0, \"Not Sunlit\", inplace=True)\n",
    "niwot_df_unload.Sunlit.mask(niwot_df_unload.Sunlit == 1, \"Sunlit Canopy\", inplace=True)\n",
    "\n",
    "# Create unloading classification column\n",
    "niwot_df_unload['Classification'] = niwot_df_unload.CD.copy(deep=True)\n",
    "niwot_df_unload.Classification.mask(niwot_df_unload.Classification == 0, \"Snow Unloading\", inplace=True)\n",
    "niwot_df_unload.Classification.mask(niwot_df_unload.Classification == 1, \"Snow Staying\", inplace=True)\n",
    "\n",
    "niwot_df_snowstay   = niwot_df_unload.where(niwot_df_unload.CD == 1).dropna(axis=0, subset=['CD']) # where CD == 1, meaning Snow Staying, make that snowstaydf\n",
    "niwot_df_snowunload = niwot_df_unload.where(niwot_df_unload.CD == 0).dropna(axis=0, subset=['CD']) # where CD == 0, meaning Snow Unloading, make that snowunloaddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a45088d-3487-491d-894c-65f9f5549c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# https://plotly.com/python/marker-style\n",
    "# TYPE-------------------------------------------------------\n",
    "# Create symbols for type 1 and type 2 \n",
    "niwot_df_unload['Typesymbol'] = np.nan\n",
    "\n",
    "# open diamont for type 1, diamond for type 2, open x circle for no classification\n",
    "niwot_df_unload['Typesymbol'].mask(niwot_df_unload['Type'] == 1, 102, inplace=True) \n",
    "niwot_df_unload['Typesymbol'].mask(niwot_df_unload['Type'] == 2., 2, inplace=True)    \n",
    "\n",
    "# then fillna with 128 for circle with x through it \n",
    "niwot_df_unload['Typesymbol'] = niwot_df_unload['Typesymbol'].fillna(128)  \n",
    "\n",
    "# SNOW-------------------------------------------------------\n",
    "# Create symbols for sunlit or not\n",
    "niwot_df_unload['Snowsymbol'] = np.nan\n",
    "\n",
    "# open triangle for melt, diamond for sub, open x circle for no classification\n",
    "# niwotdf['Snowsymbol'].mask(niwotdf['Snow'] == 'mass', 105, inplace=True) # this is working without fillna\n",
    "niwot_df_unload['Snowsymbol'].mask(niwot_df_unload['Snow'] == 'sub', 18, inplace=True)  \n",
    "# niwotdf['Snowsymbol'].mask(niwotdf['Snow'] == 'melt', 2, inplace=True)    \n",
    "\n",
    "# then fillna with 128 for circle with x through it \n",
    "niwot_df_unload['Snowsymbol'] = niwot_df_unload['Snowsymbol'].fillna(128)  \n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6e431-fe5f-4d71-b2d2-e60af4b5adfe",
   "metadata": {},
   "source": [
    "# Calculate Duration of Unloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73147d52-196d-403b-9c5f-f217dbb01337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS ITT OMG MAGIC \n",
    "opn_events = opn_df_unload.groupby((opn_df_unload[\"Classification\"] != opn_df_unload[\"Classification\"].shift()).cumsum()).agg({\"datetime\" : [\"min\", \"max\", \"count\"], \"shortwave\" : [\"mean\"], \"temp\" : [\"mean\"], \"windspeed\" : [\"mean\"], \"CD\" : [\"mean\"], \"Type\" : [\"mean\"]})\n",
    "sod_events = sod_df_unload.groupby((sod_df_unload[\"Classification\"] != sod_df_unload[\"Classification\"].shift()).cumsum()).agg({\"datetime\" : [\"min\", \"max\", \"count\"], \"shortwave\" : [\"mean\"], \"temp\" : [\"mean\"], \"windspeed\" : [\"mean\"], \"CD\" : [\"mean\"], \"Type\" : [\"mean\"]})\n",
    "niw_events = niwot_df_unload.groupby((niwot_df_unload[\"Classification\"] != niwot_df_unload[\"Classification\"].shift()).cumsum()).agg({\"datetime\" : [\"min\", \"max\", \"count\"], \"shortwave\" : [\"mean\"], \"temp\" : [\"mean\"], \"windspeed\" : [\"mean\"], \"CD\" : [\"mean\"], \"Type\" : [\"mean\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca8ac17-a574-4f62-8649-ba4d1a2f32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opn_events.to_csv('/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/Classifications/laret_open_events.csv')\n",
    "sod_events.to_csv('/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/Classifications/sodankyla_events.csv')\n",
    "niw_events.to_csv('/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/Classifications/niwot_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e9e52cf-3772-45ab-a55b-d68169c511f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only save the unloading events information\n",
    "# opn_events.CD = opn_events.CD.where(opn_events.CD == 0).dropna()\n",
    "# opn_events.dropna(inplace=True)\n",
    "\n",
    "# sod_events.CD = sod_events.CD.where(sod_events.CD == 0).dropna()\n",
    "# sod_events.dropna(inplace=True)\n",
    "\n",
    "# niw_events.CD = niw_events.CD.where(niw_events.CD == 0).dropna()\n",
    "# niw_events.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb4450-c7a0-4e54-9e52-253837de61e6",
   "metadata": {},
   "source": [
    "# editing the rest manually and then working with them somewhere else, it was too hard to get the formatting correct here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
