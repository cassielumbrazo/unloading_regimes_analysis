{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c470cef4-0003-456b-a41e-8b2197c5e6ec",
   "metadata": {},
   "source": [
    "# Niwot Statistics Notebook\n",
    "* t-tests on data with SW thresholds\n",
    "\n",
    "#### Two-Sample T-Test: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
    "* using for Niwot and Laret Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63363835-b957-44d4-ac91-cf90e6e81da0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea87c31-e23a-49e6-b16e-47bcf1660733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "%matplotlib widget\n",
    "# plotting packages \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# interactive plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# data packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "import csv \n",
    "import copy \n",
    "import os.path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c104a05-937e-4935-83a2-8d5c1debef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat packages, just for the stats notebooks\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm # create normal distribution from dataset \n",
    "from scipy.stats import chisquare #Calculate a one-way chi-square test.\n",
    "from scipy.stats import chi2_contingency #Chi-square test of independence of variables in a contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27862421-2bc9-4dcc-9bfb-ec2e62bfe13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # a module that adds some plotting capabilities and makes your plots look better\n",
    "\n",
    "sns.set() # activates some of the default settings from seaborn\n",
    "# The following settings just set some defaults for the plots\n",
    "plt.rcParams['figure.figsize']  = (12,4) #width, height\n",
    "plt.rcParams['axes.titlesize']  = 14\n",
    "plt.rcParams['axes.labelsize']  = 12\n",
    "plt.rcParams['xtick.labelsize'] = 11\n",
    "plt.rcParams['ytick.labelsize'] = 11\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "sns.set_style(\"dark\", {\"xtick.bottom\": True, 'ytick.left': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8e2b3-4c6d-4fb8-a1f6-d2349ca4ed9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and Clean datasets for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3f8971-6693-44bd-9465-8f6d2b341024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMERIFLUX MET DATA \n",
    "niwotflux =   pd.read_csv(\"/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/niwot_2017_ameriflux_unload1hr.csv\")\n",
    "niwotflux['datetime']  = pd.DatetimeIndex(niwotflux['datetime'])\n",
    "# niwotflux.index = pd.DatetimeIndex(niwotflux['datetime'])\n",
    "# niwotflux.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "# OBSERVATIONS CLASSIFICATIONS\n",
    "niwotobs =  pd.read_csv(\"/Users/Lumbr/OneDrive - UW/Documents/Washington/UnloadingRegimes/OtherSites/Classifications/datetimeformat_classifications_niwot2017.csv\")\n",
    "niwotobs['datetime'] = pd.to_datetime(niwotobs['datetime'])\n",
    "\n",
    "# niwotobs.index = pd.DatetimeIndex(niwotobs['datetime'])\n",
    "# niwotobs.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "niwotobs.dropna(axis=0, how='all', inplace=True) #removing row is entire row is NAN #careful with this, without datetime a lot gets removed \n",
    "\n",
    "# MERG THEM \n",
    "niwotdf = pd.merge(niwotflux, niwotobs, how='outer', on='datetime')\n",
    "niwotdf.index = pd.DatetimeIndex(niwotdf['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa54de5-06ff-4c34-9104-04e68c4ce54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create symbols for sunlit or not\n",
    "niwotdf['Esymbol'] = np.nan\n",
    "# niwotdf['Eminus1symbol'] = np.nan\n",
    "\n",
    "# open triangle for cloudy, diamond for sunny, open x circle for no radiation data\n",
    "niwotdf['Esymbol'].mask(niwotdf['E'] == 0., 105, inplace=True) # this is working without fillna\n",
    "niwotdf['Esymbol'].mask(niwotdf['E'] == 1., 2, inplace=True)  \n",
    "# niwotdf['Eminus1symbol'].mask(niwotdf['Eminus1symbol'] == 0., 105, inplace=True) # this is working without fillna\n",
    "# niwotdf['Eminus1symbol'].mask(niwotdf['Eminus1symbol'] == 1., 2, inplace=True)  \n",
    "\n",
    "# then fillna with 128 for circle with x through it \n",
    "niwotdf['Esymbol'] = niwotdf['Esymbol'].fillna(128) \n",
    "# niwotdf['Eminus1symbol'] = niwotdf['Eminus1symbol'].fillna(128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e133aacd-0906-485f-acfa-32009689fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seperate df for only snow in the canopy timesteps \n",
    "df_unload = niwotdf.copy(deep=True)\n",
    "df_unload = df_unload.dropna(axis=0, how='any', subset=['CD'])\n",
    "\n",
    "# Have to remove all nans for this plotting to work.... need to come back to this \n",
    "df_unload.dropna(inplace=True) #########KEEP THIS IN MIND, COME BACK TO IT\n",
    "\n",
    "# Create sunlit column\n",
    "df_unload['Sunlit'] = df_unload.E.copy(deep=True)\n",
    "df_unload.Sunlit.mask(df_unload.Sunlit == 0, \"Not Sunlit\", inplace=True)\n",
    "df_unload.Sunlit.mask(df_unload.Sunlit == 1, \"Sunlit Canopy\", inplace=True)\n",
    "\n",
    "# Create unloading classification column\n",
    "df_unload['Classification'] = df_unload.CD.copy(deep=True)\n",
    "df_unload.Classification.mask(df_unload.Classification == 0, \"Snow Unloading\", inplace=True)\n",
    "df_unload.Classification.mask(df_unload.Classification == 1, \"Snow Staying in the Canopy\", inplace=True)\n",
    "\n",
    "snowstaydf   = df_unload.where(df_unload.CD == 1).dropna() # where CD == 1, meaning Snow Staying, make that snowstaydf\n",
    "snowunloaddf = df_unload.where(df_unload.CD == 0).dropna() # where CD == 0, meaning Snow Unloading, make that snowunloaddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22fb774-0650-409f-b85d-9a3f66377d5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee372500-0d75-4db0-89dc-f84ed1825707",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define some plotting constants for easier coding \n",
    "plt.close('all')\n",
    "\n",
    "# Colors\n",
    "colornosnow = '#D2B48C' # nice tan\n",
    "colorsnow = '#7dcfd4' # slightly desaturated cyan\n",
    "colorsnowunload = '#1F15D5' # bright, deep blue \n",
    "colorsunny = '#E4E44A' # trying a little less bright \n",
    "\n",
    "# Names\n",
    "namesnow = 'Snow Staying'\n",
    "namesnowunload = 'Snow Unloading'\n",
    "group_labels = ['Snow Staying', 'Snow Unloading']\n",
    "\n",
    "nametemp = \"Air Temperature (C)\"\n",
    "namewind = \"Wind Speed (m/s)\"\n",
    "nameSW = \"Shortwave (W/m2)\"\n",
    "\n",
    "# colors and names \n",
    "color1='tomato'; color2='maroon'; color3='navy'\n",
    "colors = [color1, color2, color3]\n",
    "\n",
    "# name1 = '600 < SW'; name2 = '400 < SW < 600'; name3 = '400 > SW'\n",
    "name1 = 'SW > 600'; name2 = '400 < SW < 600'; name3 = 'SW < 400'\n",
    "label = [name1, name2, name3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ef6ac-5ed7-4424-85f8-8a16875aa748",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make thresholded datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e044ce8-e130-48d3-b05d-3d72500b8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the df we want, and then going to classify it by SW threshold\n",
    "dfSW600 =    df_unload.copy(deep=True) # SW > 600\n",
    "dfSW400600 = df_unload.copy(deep=True) # SW between 400-600\n",
    "dfSW400 =    df_unload.copy(deep=True) # SW < 400\n",
    "\n",
    "# Create for temperature threshold \n",
    "dfTg0 =    df_unload.copy(deep=True) # Temp g(greater) 0\n",
    "dfTl0 =    df_unload.copy(deep=True) # Temp l(less)    0 \n",
    "\n",
    "# Creating df with only SW > 600\n",
    "dfSW600.mask(dfSW600.shortwave < 600, inplace=True) # we want where SW > 600, else nan\n",
    "dfSW600.dropna(inplace=True) # and drop all nan... \n",
    "dfSW600stay   = dfSW600.where(dfSW600.CD == 1).dropna()\n",
    "dfSW600unload = dfSW600.where(dfSW600.CD == 0).dropna()\n",
    "\n",
    "# Creating df with onyl 400 < SW < 600\n",
    "dfSW400600.mask(dfSW400600.shortwave > 600, inplace=True) # we want where SW < 600, \n",
    "dfSW400600.mask(dfSW400600.shortwave < 400, inplace=True) # and SW > 400, else nan\n",
    "dfSW400600.dropna(inplace=True) # and drop all nan... \n",
    "dfSW400600stay   = dfSW400600.where(dfSW400600.CD == 1).dropna()\n",
    "dfSW400600unload = dfSW400600.where(dfSW400600.CD == 0).dropna()\n",
    "\n",
    "# Creating df with SW < 400\n",
    "dfSW400.mask(dfSW400.shortwave > 400, inplace=True) # we want where SW < 400, else nan\n",
    "dfSW400.dropna(inplace=True) # and drop all nan...\n",
    "dfSW400stay   = dfSW400.where(dfSW400.CD == 1).dropna()\n",
    "dfSW400unload = dfSW400.where(dfSW400.CD == 0).dropna()\n",
    "\n",
    "# Create df with T > 0 \n",
    "dfTg0.mask(dfTg0.temp < 0, inplace=True) # we want where T > 0, else nan\n",
    "dfTg0.dropna(inplace=True) \n",
    "dfTg0stay   = dfTg0.where(dfTg0.CD == 1).dropna()\n",
    "dfTg0unload = dfTg0.where(dfTg0.CD == 0).dropna()\n",
    "\n",
    "# Create df with T < 0 \n",
    "dfTl0.mask(dfTl0.temp > 0, inplace=True) # we want where T < 0, else nan \n",
    "dfTl0.dropna(inplace=True)\n",
    "dfTl0stay   = dfTl0.where(dfTl0.CD == 1).dropna()\n",
    "dfTl0unload = dfTl0.where(dfTl0.CD == 0).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fcfdd-9538-49f3-b375-4ce9d196ccdf",
   "metadata": {},
   "source": [
    "# Statistics \n",
    "* taking code from Laret Statistics_1.ipyb notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d23ec-1513-433e-a75a-919a31b76296",
   "metadata": {
    "tags": []
   },
   "source": [
    "## T-Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687f6a9-f88f-4251-ba4b-72ee1a4b676b",
   "metadata": {},
   "source": [
    "#### All Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9070988-d647-4efe-9933-b1987a6e0e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=7.594783821694393, pvalue=1.0005378370793078e-13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(snowunloaddf['temp'], snowstaydf['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d2471dd-8c2d-4272-9b51-1669b350c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=16.056309181851557, pvalue=1.4740720436900322e-49)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(snowunloaddf['shortwave'], snowstaydf['shortwave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f84003-179b-43a6-8a16-c6808418414a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=10.1884610727472, pvalue=8.232606762441789e-23)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(snowunloaddf['windspeed'], snowstaydf['windspeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc5329-0da9-427b-97bc-8197a663d5b3",
   "metadata": {},
   "source": [
    "### Shortwave Thresholded Data\n",
    "**SW > 600**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c615ac9d-7fe6-47e8-84de-8e19545f8f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-3.9832554591177463, pvalue=0.00014895004522626163)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfSW600stay['temp'], dfSW600unload['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "243aa04a-c145-4342-bd29-a36410a8fd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.1560381890134284, pvalue=0.2511062975873969)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfSW600stay['windspeed'], dfSW600unload['windspeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45159ac-ea7f-427a-b398-1871908c7815",
   "metadata": {},
   "source": [
    "**400 < SW < 600**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f290294b-16fc-49d1-9581-c7f51ad4d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.5890557714408284, pvalue=0.11649127739605475)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfSW400600stay['temp'], dfSW400600unload['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cff2ebf9-d698-42d8-bb45-0f8bb7ac0975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.2518482174535521, pvalue=0.21473365956192184)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfSW400600stay['windspeed'], dfSW400600unload['windspeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7612b8d-446f-4812-bdf8-d02ab370612e",
   "metadata": {},
   "source": [
    "**SW < 400**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e5d172d-3441-4b37-b17d-be9428bb69db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-3.0642578274204793, pvalue=0.0022914838721290872)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfSW400stay['temp'], dfSW400unload['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bcff89c-88f7-4d99-a627-d243127e6582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-6.960955393857682, pvalue=9.876478843150137e-12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfSW400stay['windspeed'], dfSW400unload['windspeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9552e5-4a7e-4961-850f-b7e5786e2c25",
   "metadata": {},
   "source": [
    "### Temperature Thresholded Data \n",
    "**T>0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9f89ede-cb30-4993-baee-4f21baadfd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-3.5815874139892365, pvalue=0.0007151629436889473)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfTg0stay['shortwave'], dfTg0unload['shortwave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "751ba7a0-7b88-4078-a9a9-b0169b62ff4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.248493244693405, pvalue=0.0019635607449520454)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfTg0stay['windspeed'], dfTg0unload['windspeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c53b29-5d65-4314-9a4a-cda245663030",
   "metadata": {},
   "source": [
    "**T<0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b4c2e8f-c194-4074-9520-a415d787945f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-12.776329341984717, pvalue=1.9798780328604836e-33)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfTl0stay['shortwave'], dfTl0unload['shortwave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32f55a88-537f-4232-8d97-866545585b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-12.113935036606446, pvalue=1.558783481796821e-30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(dfTl0stay['windspeed'], dfTl0unload['windspeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8128cd30-22d2-4af3-838e-0c28eb08fed2",
   "metadata": {},
   "source": [
    "_____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711e66f1-9b4c-4a17-afe1-61702162a1a9",
   "metadata": {},
   "source": [
    "## Z-Score, continued\n",
    "* Simplify this into one block of code to run for all the other subsets of data \n",
    "\n",
    "#### Shortwave Thresholded Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "098d81cf-d20f-4c48-a228-1d8be8119eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full dataset \n",
    "var1 = snowstaydf['temp']\n",
    "var2 = snowunloaddf['temp']\n",
    "\n",
    "# var1 = snowstaydf['shortwave']\n",
    "# var2 = snowunloaddf['shortwave']\n",
    "\n",
    "# var1 = snowstaydf['windspeed']\n",
    "# var2 = snowunloaddf['windspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57ca8e98-9a4b-4dd7-b829-3a62c9b64244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snow Stay Sample Size:  465\n",
      "Snow Unload Sample Size:  230\n",
      "z_alpha = 1.6448536269514722\n",
      "z-score = -7.679\n",
      "p = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check that we have a large enough sample size (n>30)\n",
    "n = len(var1)\n",
    "print(\"Snow Stay Sample Size: \", n)\n",
    "m = len(var2)\n",
    "print(\"Snow Unload Sample Size: \", m)\n",
    "\n",
    "# We want alpha to be 0.05 \n",
    "alpha = 0.05 \n",
    "\n",
    "# Which gives a confidence of 0.95\n",
    "conf = 1 - alpha \n",
    "\n",
    "# Determine which value in the z-distribution corresponds to the 0.95 confidence in the CDF\n",
    "z_alpha = stats.norm.ppf(conf)\n",
    "print(\"z_alpha = {}\".format(z_alpha))\n",
    "\n",
    "# Compuate the pooled standard deviation \n",
    "pooled_sd = np.sqrt(var1.std(ddof=1)**2 / n + var2.std(ddof=1)**2 / m )\n",
    "\n",
    "# Hypothesizing no change\n",
    "mu_0 = 0\n",
    "\n",
    "# Compute z-score\n",
    "zscore = (var1.mean() - var2.mean() - mu_0)/pooled_sd\n",
    "print(\"z-score = {}\".format( np.round(zscore,3) )) \n",
    "\n",
    "# Compute p-value from z-score\n",
    "pvalue = 1 - stats.norm.cdf(zscore)\n",
    "print(\"p = {}\".format( np.round(pvalue,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2900306-f6d5-431c-96eb-6a3e66e2ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For SW thresholds \n",
    "# # SW > 600\n",
    "# var1 = dfSW600stay['temp']\n",
    "# var2 = dfSW600unload['temp']\n",
    "# var1 = dfSW600stay['windspeed']\n",
    "# var2 = dfSW600unload['windspeed']\n",
    "\n",
    "# # 400 < SW < 600\n",
    "# var1 = dfSW400600stay['temp']\n",
    "# var2 = dfSW400600unload['temp']\n",
    "# var1 = dfSW400600stay['windspeed']\n",
    "# var2 = dfSW400600unload['windspeed']\n",
    "\n",
    "# # SW < 400\n",
    "var1 = dfSW400stay['temp']\n",
    "var2 = dfSW400unload['temp']\n",
    "# var1 = dfSW400stay['windspeed']\n",
    "# var2 = dfSW400unload['windspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a982f29d-7b0f-40d7-b5a4-9d8790300b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snow Stay Sample Size:  427\n",
      "Snow Unload Sample Size:  113\n",
      "z_alpha = 1.6448536269514722\n",
      "z-score = -3.135\n",
      "p = 0.999\n"
     ]
    }
   ],
   "source": [
    "# Check that we have a large enough sample size (n>30)\n",
    "n = len(var1)\n",
    "print(\"Snow Stay Sample Size: \", n)\n",
    "m = len(var2)\n",
    "print(\"Snow Unload Sample Size: \", m)\n",
    "\n",
    "# We want alpha to be 0.05 \n",
    "alpha = 0.05 \n",
    "\n",
    "# Which gives a confidence of 0.95\n",
    "conf = 1 - alpha \n",
    "\n",
    "# Determine which value in the z-distribution corresponds to the 0.95 confidence in the CDF\n",
    "z_alpha = stats.norm.ppf(conf)\n",
    "print(\"z_alpha = {}\".format(z_alpha))\n",
    "\n",
    "# Compuate the pooled standard deviation \n",
    "pooled_sd = np.sqrt(var1.std(ddof=1)**2 / n + var2.std(ddof=1)**2 / m )\n",
    "\n",
    "# Hypothesizing no change\n",
    "mu_0 = 0\n",
    "\n",
    "# Compute z-score\n",
    "zscore = (var1.mean() - var2.mean() - mu_0)/pooled_sd\n",
    "print(\"z-score = {}\".format( np.round(zscore,3) )) \n",
    "\n",
    "# Compute p-value from z-score\n",
    "pvalue = 1 - stats.norm.cdf(zscore)\n",
    "print(\"p = {}\".format( np.round(pvalue,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4adfbed-644f-4689-ad86-18ebe698c217",
   "metadata": {},
   "source": [
    "#### Temperature Thresholded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c342bf13-8d67-44b8-a94e-977c63004c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For temperature thresholds \n",
    "# var1 = dfTg0stay['windspeed']\n",
    "# var2 = dfTg0unload['windspeed']\n",
    "# var1 = dfTg0stay['shortwave']\n",
    "# var2 = dfTg0unload['shortwave']\n",
    "\n",
    "var1 = dfTl0stay['windspeed']\n",
    "var2 = dfTl0unload['windspeed']\n",
    "# var1 = dfTl0stay['shortwave']\n",
    "# var2 = dfTl0unload['shortwave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50b64a5d-83f7-4f88-95be-4fa20967926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snow Stay Sample Size:  458\n",
      "Snow Unload Sample Size:  179\n",
      "z_alpha = 1.6448536269514722\n",
      "z-score = -11.151\n",
      "p = 1.0\n",
      "p = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Check that we have a large enough sample size (n>30)\n",
    "n = len(var1)\n",
    "print(\"Snow Stay Sample Size: \", n)\n",
    "m = len(var2)\n",
    "print(\"Snow Unload Sample Size: \", m)\n",
    "\n",
    "# We want alpha to be 0.05 \n",
    "alpha = 0.05 \n",
    "\n",
    "# Which gives a confidence of 0.95\n",
    "conf = 1 - alpha \n",
    "\n",
    "# Determine which value in the z-distribution corresponds to the 0.95 confidence in the CDF\n",
    "z_alpha = stats.norm.ppf(conf)\n",
    "print(\"z_alpha = {}\".format(z_alpha))\n",
    "\n",
    "# Compuate the pooled standard deviation \n",
    "pooled_sd = np.sqrt(var1.std(ddof=1)**2 / n + var2.std(ddof=1)**2 / m )\n",
    "\n",
    "# Hypothesizing no change\n",
    "mu_0 = 0\n",
    "\n",
    "# Compute z-score\n",
    "zscore = (var1.mean() - var2.mean() - mu_0)/pooled_sd\n",
    "print(\"z-score = {}\".format( np.round(zscore,3) )) \n",
    "\n",
    "# Compute p-value from z-score\n",
    "pvalue = 1 - stats.norm.cdf(zscore)\n",
    "pvalue2 = stats.norm.cdf(zscore)\n",
    "print(\"p = {}\".format( np.round(pvalue,3)))\n",
    "print(\"p = {}\".format( np.round(pvalue2,3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
